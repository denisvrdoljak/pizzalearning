{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "import codecs\n",
    "import json\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "def read_dataset(path):\n",
    "  with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "  dataset = json.loads(content)\n",
    "  return dataset\n",
    "\n",
    "path = 'data/pizza_request_dataset.json'\n",
    "dataset = read_dataset(path)\n",
    "shuffle = np.random.permutation(np.arange(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data and split into training and dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all = pd.read_json(path)\n",
    "data_all = data_all.ix[shuffle]\n",
    "\n",
    "data_all['hour_of_request'] = pd.to_datetime(data_all.unix_timestamp_of_request_utc.values, unit='s').hour\n",
    "data_all['length_of_title'] = [len(entry.split()) for entry in data_all.request_title.values]\n",
    "data_all['length_of_text'] = [len(entry.split()) for entry in data_all.request_text_edit_aware.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631, 17)\n"
     ]
    }
   ],
   "source": [
    "kaggle_test_data = pd.read_json('data/test.json')\n",
    "print kaggle_test_data.shape\n",
    "\n",
    "kaggle_test_data['hour_of_request'] = pd.to_datetime(kaggle_test_data.unix_timestamp_of_request_utc.values, unit='s').hour\n",
    "kaggle_test_data['length_of_title'] = [len(entry.split()) for entry in kaggle_test_data.request_title.values]\n",
    "kaggle_test_data['length_of_text'] = [len(entry.split()) for entry in kaggle_test_data.request_text_edit_aware.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 36)\n",
      "(1702, 36)\n"
     ]
    }
   ],
   "source": [
    "train_all = data_all[:int(len(data_all) * 0.7)]\n",
    "test_all = data_all[int(len(data_all) * 0.7):]\n",
    "\n",
    "print train_all.shape\n",
    "print test_all.shape\n",
    "\n",
    "train_data_text = train_all.request_text_edit_aware.values\n",
    "train_labels = train_all.requester_received_pizza.values\n",
    "\n",
    "test_data_text= test_all.request_text_edit_aware.values\n",
    "test_labels = test_all.requester_received_pizza.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s '\n"
     ]
    }
   ],
   "source": [
    "# linya: preprocessor for text\n",
    "def text_preprocesspr(s):\n",
    "    #lowercase does improve result a little bit\n",
    "    return s.lower()\n",
    "\n",
    "    #strip space does not improve \n",
    "    #return s.lower().strip()\n",
    "\n",
    "#sample usage\n",
    "print \"'\" + text_preprocesspr(\"S \") + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linya: read from vocabulary provided in kaggle dataset\n",
    "def get_vocabulary(filename):\n",
    "    text_file = open(\"data/narratives/%s.txt\" % (filename), \"r\")\n",
    "    lines = text_file.read().split('\\n')\n",
    "    return lines\n",
    "\n",
    "def get_vocabulary_all():\n",
    "    filenames = [\"desire\", \"money\", \"job\", \"family\", \"student\"]\n",
    "    result = set()\n",
    "    for filename in filenames:\n",
    "        lines = get_vocabulary(filename)\n",
    "        for i in range(len(lines)):\n",
    "            result.add(lines[i].lower())\n",
    "    return result\n",
    "\n",
    "preset_vocabulary = get_vocabulary_all() \n",
    "#checked, this is included in current vocabulary already\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: helper function to easily compare performance\n",
    "def comapre_features(train_data, test_data, text_field = 'request_text_edit_aware', add_features_list=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    train_labels = train_data.requester_received_pizza.values\n",
    "\n",
    "    test_data_text= test_data[text_field].values\n",
    "    test_labels = test_data.requester_received_pizza.values\n",
    "    \n",
    "    vec_train = CountVectorizer(preprocessor = text_preprocesspr)\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_, preprocessor = text_preprocesspr)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "    \n",
    "    LR_train = LogisticRegression()\n",
    "    LR_train.fit(tokenized_train_data,train_labels)\n",
    "\n",
    "    test_pred = LR_train.predict(tokenized_test_data)\n",
    "    print \"------ NLP Baseline: ------\\n\"\n",
    "    print(classification_report(test_labels, test_pred))\n",
    "    print '\\n'\n",
    "    \n",
    "    if add_features_list:\n",
    "        train_token_mat = tokenized_train_data.toarray()\n",
    "        test_token_mat = tokenized_test_data.toarray()\n",
    "        \n",
    "        features_added = []\n",
    "        for feature in add_features_list:\n",
    "            features_added.append(feature)\n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "            \n",
    "            LR_train_plus = LogisticRegression()\n",
    "            LR_train_plus.fit(train_token_mat, train_labels)\n",
    "            test_pred_plus = LR_train_plus.predict(test_token_mat)\n",
    "            print \"--- Features = {feature}: ---\\n\".format(feature=features_added)\n",
    "            print classification_report(test_labels, test_pred_plus)\n",
    "            print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: helper function to make a classifier based on a list of extra features\n",
    "def make_classifier(train_data, test_data, text_field = 'request_text_edit_aware', add_features_list=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    train_labels = train_data.requester_received_pizza.values\n",
    "\n",
    "    test_data_text= test_data[text_field].values    \n",
    "    \n",
    "    vec_train = CountVectorizer(preprocessor = text_preprocesspr)\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_, preprocessor = text_preprocesspr)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)    \n",
    "    \n",
    "    train_token_mat = tokenized_train_data.toarray()\n",
    "    test_token_mat = tokenized_test_data.toarray()\n",
    "    if add_features_list:                \n",
    "        features_added = []\n",
    "        for feature in add_features_list:\n",
    "            features_added.append(feature)\n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "            \n",
    "    LR_train_plus = LogisticRegression()\n",
    "    LR_train_plus.fit(train_token_mat, train_labels)\n",
    "    return LR_train_plus, test_token_mat    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING: Look at subreddits matrix\n",
    "\n",
    "Had this idea: maybe the people giving / requesting pizza belong to a similar group (e.g. gamers tend to give pizzas to fellow gamers, or people who look more 'legit' by the subredits they participate in will tend to receive pizzas)\n",
    "\n",
    "The implementation is simple:\n",
    "1. Extract all the unique subreddits from the training_data as **all_unique_subreddits**\n",
    "2. Construct a matrix for each observation, if the requester has subreddits in ith element of **all_unique_subreddits**, then fill a 1, otherwise 0\n",
    "3. Concatenante this matrix to the tokenized text data\n",
    "4. Train the model with LogisticRegression\n",
    "5. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: a helper function to construct the subreddit matrix for each observation in step 2\n",
    "def make_subreddits_matrix(input_data, unique_subreddits):\n",
    "    results = []\n",
    "    for entry in input_data:\n",
    "        results.append(np.in1d(unique_subreddits, entry))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unique_subreddits = np.unique(np.concatenate(train_all.requester_subreddits_at_request.values))\n",
    "all_unique_subreddits.shape\n",
    "\n",
    "subreddits_matrix_train_all = make_subreddits_matrix(train_all.requester_subreddits_at_request.values, \n",
    "                                                     all_unique_subreddits)\n",
    "subreddits_matrix_test_all = make_subreddits_matrix(test_all.requester_subreddits_at_request.values, \n",
    "                                                    all_unique_subreddits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I just ran a simple Bernoulli Naive-Bayes classifier to do a quick sanity check. If this feature is any good, the NB performance shouldn't be too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.90      0.82      1276\n",
      "       True       0.30      0.13      0.19       426\n",
      "\n",
      "avg / total       0.64      0.71      0.66      1702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(np.array(subreddits_matrix_train_all), train_labels)\n",
    "\n",
    "test_pred = nb.predict(np.array(subreddits_matrix_test_all))\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite interestingly, using a NB on the subreddits matrix *alone* gives us approximately the same performance we got with tokenizing the texts. Hmm, looks promising. How about we try to make a classifier and see what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_text = train_all.request_text_edit_aware.values\n",
    "train_labels = train_all.requester_received_pizza.values\n",
    "\n",
    "test_data_text= test_all.request_text_edit_aware.values\n",
    "test_labels = test_all.requester_received_pizza.values\n",
    "\n",
    "vec_train = CountVectorizer(preprocessor = text_preprocesspr)\n",
    "tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_, preprocessor = text_preprocesspr)\n",
    "tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "\n",
    "train_token_mat = tokenized_train_data.toarray()\n",
    "test_token_mat = tokenized_test_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1276\n",
      "       True       0.36      0.24      0.29       426\n",
      "\n",
      "avg / total       0.67      0.70      0.68      1702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_train_plus = LogisticRegression()\n",
    "LR_train_plus.fit(np.concatenate((train_token_mat, subreddits_matrix_train_all), axis=1), train_labels)\n",
    "\n",
    "test_pred_plus = LR_train_plus.predict(np.concatenate((test_token_mat, subreddits_matrix_test_all), axis=1))\n",
    "\n",
    "print classification_report(test_labels, test_pred_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results on test_data above looks like an overall improvement. Let's go ahead and make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "subreddits_kaggle_test_data = make_subreddits_matrix(kaggle_test_data.requester_subreddits_at_request.values,\n",
    "                                                     all_unique_subreddits)\n",
    "\n",
    "tokenized_test_data = vec_test.fit_transform(kaggle_test_data.request_text_edit_aware.values)\n",
    "test_token_mat = tokenized_test_data.toarray()\n",
    "test_token_mat = np.concatenate((test_token_mat, subreddits_kaggle_test_data), axis=1)\n",
    "\n",
    "pred_test_all = LR_train_plus.predict(test_token_mat)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['request_id'] = kaggle_test_data.request_id\n",
    "#maxyan: sample submission was expecting 0 instead of False\n",
    "predictions['requester_received_pizza'] = pred_test_all.astype(int)\n",
    "predictions = predictions.set_index('request_id')\n",
    "\n",
    "# make sure the length is as expected in https://www.kaggle.com/c/random-acts-of-pizza/submissions/attach\n",
    "print len(predictions) == 1631\n",
    "predictions.to_csv('max_nlp_plus_features_submission_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some final words on my bit of exploration**\n",
    "\n",
    "Throughout the exercise, I used the originally shuffled and *splitted* data for training and testing. I haven't bothered making any changes. I'm not sure if we can further improve the performance if we took the entire dataset for training.\n",
    "\n",
    "\n",
    "Also, I have been using Ricardo's dataset (i.e. 'data/pizza_request_dataset.json') rather than the one provided by Kaggle. I think there are some differences but I haven't figured out what exactly these differences are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 12055)\n",
      "(1702, 12055)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.85      0.81      1274\n",
      "       True       0.33      0.21      0.26       428\n",
      "\n",
      "avg / total       0.66      0.69      0.67      1702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_train = CountVectorizer(preprocessor = text_preprocesspr)\n",
    "tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_, preprocessor = text_preprocesspr)\n",
    "tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "\n",
    "print tokenized_train_data.shape\n",
    "print tokenized_test_data.shape\n",
    "\n",
    "LR_train = LogisticRegression()\n",
    "LR_train.fit(tokenized_train_data,train_labels)\n",
    "\n",
    "test_pred = LR_train.predict(tokenized_test_data)\n",
    "\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['giver_username_if_known',\n",
       " 'request_id',\n",
       " 'request_text_edit_aware',\n",
       " 'request_title',\n",
       " 'requester_account_age_in_days_at_request',\n",
       " 'requester_days_since_first_post_on_raop_at_request',\n",
       " 'requester_number_of_comments_at_request',\n",
       " 'requester_number_of_comments_in_raop_at_request',\n",
       " 'requester_number_of_posts_at_request',\n",
       " 'requester_number_of_posts_on_raop_at_request',\n",
       " 'requester_number_of_subreddits_at_request',\n",
       " 'requester_subreddits_at_request',\n",
       " 'requester_upvotes_minus_downvotes_at_request',\n",
       " 'requester_upvotes_plus_downvotes_at_request',\n",
       " 'requester_username',\n",
       " 'unix_timestamp_of_request',\n",
       " 'unix_timestamp_of_request_utc',\n",
       " 'hour_of_request',\n",
       " 'length_of_title',\n",
       " 'length_of_text']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kaggle_test_data.columns.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ NLP Baseline: ------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.85      0.81      1274\n",
      "       True       0.33      0.21      0.26       428\n",
      "\n",
      "avg / total       0.66      0.69      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1274\n",
      "       True       0.35      0.23      0.28       428\n",
      "\n",
      "avg / total       0.66      0.70      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1274\n",
      "       True       0.35      0.23      0.28       428\n",
      "\n",
      "avg / total       0.66      0.70      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1274\n",
      "       True       0.35      0.23      0.27       428\n",
      "\n",
      "avg / total       0.66      0.70      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1274\n",
      "       True       0.36      0.23      0.28       428\n",
      "\n",
      "avg / total       0.66      0.70      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1274\n",
      "       True       0.35      0.22      0.27       428\n",
      "\n",
      "avg / total       0.66      0.70      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title', 'hour_of_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.86      0.81      1274\n",
      "       True       0.35      0.23      0.28       428\n",
      "\n",
      "avg / total       0.66      0.70      0.68      1702\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comapre_features(train_all, \n",
    "                 test_all, \n",
    "                 add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                   'requester_number_of_subreddits_at_request',\n",
    "                                   'requester_upvotes_minus_downvotes_at_request',\n",
    "                                   'length_of_text',\n",
    "                                   'length_of_title',\n",
    "                                   'hour_of_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ NLP Baseline: ------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.75      0.93      0.83      1274\n",
      "       True       0.30      0.09      0.14       428\n",
      "\n",
      "avg / total       0.64      0.72      0.66      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.93      0.83      1274\n",
      "       True       0.34      0.11      0.17       428\n",
      "\n",
      "avg / total       0.65      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.93      0.83      1274\n",
      "       True       0.35      0.12      0.18       428\n",
      "\n",
      "avg / total       0.66      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.93      0.83      1274\n",
      "       True       0.34      0.11      0.17       428\n",
      "\n",
      "avg / total       0.65      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.92      0.83      1274\n",
      "       True       0.38      0.14      0.20       428\n",
      "\n",
      "avg / total       0.66      0.73      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.92      0.83      1274\n",
      "       True       0.37      0.13      0.20       428\n",
      "\n",
      "avg / total       0.66      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title', 'hour_of_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.92      0.83      1274\n",
      "       True       0.36      0.14      0.20       428\n",
      "\n",
      "avg / total       0.66      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comapre_features(train_all, \n",
    "                 test_all, \n",
    "                 text_field='request_title',\n",
    "                 add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                   'requester_number_of_subreddits_at_request',\n",
    "                                   'requester_upvotes_minus_downvotes_at_request',\n",
    "                                   'length_of_text',\n",
    "                                   'length_of_title',\n",
    "                                   'hour_of_request'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a classifier and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier, kaggle_test_mat = make_classifier(train_all, \n",
    "                                              kaggle_test_data, \n",
    "                                              add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                                                 'requester_number_of_subreddits_at_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier, kaggle_test_mat = make_classifier(train_all, \n",
    "                                              kaggle_test_data, \n",
    "                                              add_features_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "pred_test_all = classifier.predict(kaggle_test_mat)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['request_id'] = kaggle_test_data.request_id\n",
    "#maxyan: sample submission was expecting 0 instead of False\n",
    "predictions['requester_received_pizza'] = pred_test_all.astype(int)\n",
    "predictions = predictions.set_index('request_id')\n",
    "\n",
    "# make sure the length is as expected in https://www.kaggle.com/c/random-acts-of-pizza/submissions/attach\n",
    "print len(predictions) == 1631\n",
    "predictions.to_csv('max_nlp_plus_features_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
