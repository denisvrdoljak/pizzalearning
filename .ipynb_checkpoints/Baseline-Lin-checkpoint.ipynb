{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple baseline for Pizza project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# pandas for reading json file\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all = pd.read_json('data/train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_title = data_all.request_title\n",
    "data_text = data_all.request_text_edit_aware\n",
    "data_label = data_all.requester_received_pizza\n",
    "\n",
    "train_data_title = data_title[0:1000]\n",
    "train_data_text = data_text[0:1000]\n",
    "train_labels = data_label[0:1000]\n",
    "\n",
    "test_data_title = data_title[1000:2000]\n",
    "test_data_text = data_text[1000:2000]\n",
    "test_labels = data_label[1000:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCountVectorizerStats(cv, train_data):\n",
    "    #fit using training data\n",
    "    output = cv.fit_transform(train_data)\n",
    "    numSample, numFeatuer = output.shape\n",
    "    print \"[n_samples, n_features]: %d, %d\" % (numSample,numFeatuer)\n",
    "    print \"size of vocabulary: %d\" % (numFeatuer)\n",
    "    \n",
    "    nonZeroCount = output.nnz\n",
    "    print \"the count of explicitly-stored values (nonzeros): %d\" % (nonZeroCount)\n",
    "    print \"the average number of non-zero features per sample: %.2f\" % (1.0*nonZeroCount/numSample)\n",
    "    print \"fraction of the entries in the matrix are non-zero: %.2f percent\" % (100.0*nonZeroCount/(numSample*numFeatuer))\n",
    "    \n",
    "    featureNames = cv.get_feature_names()\n",
    "    print 'first feature name:', featureNames[0], '\\n\\rlast feature name:', featureNames[len(featureNames)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------using default vocabulary\n",
      "[n_samples, n_features]: 1000, 2070\n",
      "size of vocabulary: 2070\n",
      "the count of explicitly-stored values (nonzeros): 11567\n",
      "the average number of non-zero features per sample: 11.57\n",
      "fraction of the entries in the matrix are non-zero: 0.56 percent\n",
      "first feature name: 000 \n",
      "last feature name: zucchini\n",
      "-------------using 1-3 ngram with min_df = 10\n",
      "[n_samples, n_features]: 1000, 290\n",
      "size of vocabulary: 290\n",
      "the count of explicitly-stored values (nonzeros): 9710\n",
      "the average number of non-zero features per sample: 9.71\n",
      "fraction of the entries in the matrix are non-zero: 3.35 percent\n",
      "first feature name: about \n",
      "last feature name: you\n"
     ]
    }
   ],
   "source": [
    "def P1(train_data):\n",
    "    \n",
    "    #using content because the input is expected to be the sequence strings or bytes items \n",
    "    print '-------------using default vocabulary'\n",
    "    cv1 = CountVectorizer(input='content')\n",
    "    getCountVectorizerStats(cv1, train_data)\n",
    "    \n",
    "    print '-------------using 1-3 ngram with min_df = 10'\n",
    "    cv5 = CountVectorizer(input='content', analyzer = 'word', ngram_range=(1,3), min_df=10)\n",
    "    getCountVectorizerStats(cv5,train_data)\n",
    "    \n",
    "P1(train_data_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preditStats(preds, labels):\n",
    "    correct, total = 0, 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        if pred == label: correct += 1\n",
    "        total += 1\n",
    "    print 'total: %3d  correct: %3d  accuracy: %3.2f' %(total, correct, 1.0*correct/total)\n",
    "    f1 = metrics.f1_score(labels, preds, average='binary')\n",
    "    print 'metrics.f1_score:', f1\n",
    "    return f1\n",
    "\n",
    "def myKNN(cv_train_data, cv_test_data, k=1):\n",
    "    print '-------------using KNeighborsClassifier with k=', k\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(cv_train_data, train_labels)\n",
    "    #predict test labels using test data\n",
    "    preds = clf.predict(cv_test_data)\n",
    "    preditStats(preds, test_labels)\n",
    "    return preds\n",
    "\n",
    "def myMultinomialNB(cv_train_data, cv_test_data, a = 1.0):\n",
    "    print '-------------using MultinomialNB with alpha=', a\n",
    "    nb = MultinomialNB(alpha=a)\n",
    "    nb.fit(cv_train_data, train_labels)\n",
    "    #predict test labels using test data\n",
    "    preds = nb.predict(cv_test_data)\n",
    "    preditStats(preds, test_labels)\n",
    "    return preds\n",
    "    \n",
    "def myLogisticRegression(cv_train_data, cv_test_data, c):\n",
    "    print '-------------using LogisticRegression with penalty=l2 and C:', c\n",
    "    lr = LogisticRegression(penalty='l2', C=c)\n",
    "    lr.fit(cv_train_data, train_labels)\n",
    "    preds = lr.predict(cv_test_data)\n",
    "    preditStats(preds, test_labels)\n",
    "    print 'lr.coef_.shape:',lr.coef_.shape\n",
    "    sumOfSquareAllClasses = []\n",
    "    for iClass in range(lr.coef_.shape[0]):\n",
    "        # for class i\n",
    "        sumOfSquare = 0\n",
    "        for jFeature in range(lr.coef_.shape[1]): \n",
    "            #for feature j\n",
    "            sumOfSquare += lr.coef_[iClass][jFeature]*lr.coef_[iClass][jFeature]\n",
    "        sumOfSquareAllClasses.append(sumOfSquare)\n",
    "    print 'sumOfSquareAllClasses', sumOfSquareAllClasses\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (1000L,)\n",
      "cv_train_data.shape: (1000, 2070)\n",
      "len(featureNames): 2070\n",
      "test_data.shape (1000L,)\n",
      "cv_test_data.shape (1000, 2070)\n",
      "-------------using KNeighborsClassifier with k= 1\n",
      "total: 1000  correct: 676  accuracy: 0.68\n",
      "metrics.f1_score: 0.114754098361\n",
      "-------------using KNeighborsClassifier with k= 2\n",
      "total: 1000  correct: 745  accuracy: 0.74\n",
      "metrics.f1_score: 0.0229885057471\n",
      "-------------using KNeighborsClassifier with k= 3\n",
      "total: 1000  correct: 707  accuracy: 0.71\n",
      "metrics.f1_score: 0.0928792569659\n",
      "-------------using MultinomialNB with alpha= 0.0\n",
      "total: 1000  correct: 701  accuracy: 0.70\n",
      "metrics.f1_score: 0.250626566416\n",
      "-------------using MultinomialNB with alpha= 0.5\n",
      "total: 1000  correct: 710  accuracy: 0.71\n",
      "metrics.f1_score: 0.198895027624\n",
      "-------------using MultinomialNB with alpha= 1.0\n",
      "total: 1000  correct: 737  accuracy: 0.74\n",
      "metrics.f1_score: 0.120401337793\n",
      "-------------using LogisticRegression with penalty=l2 and C: 1.0\n",
      "total: 1000  correct: 700  accuracy: 0.70\n",
      "metrics.f1_score: 0.132947976879\n",
      "lr.coef_.shape: (1L, 2070L)\n",
      "sumOfSquareAllClasses [174.82458226316612]\n",
      "-------------using LogisticRegression with penalty=l2 and C: 10.0\n",
      "total: 1000  correct: 654  accuracy: 0.65\n",
      "metrics.f1_score: 0.195348837209\n",
      "lr.coef_.shape: (1L, 2070L)\n",
      "sumOfSquareAllClasses [1452.9130663630067]\n",
      "-------------using LogisticRegression with penalty=l2 and C: 100.0\n",
      "total: 1000  correct: 644  accuracy: 0.64\n",
      "metrics.f1_score: 0.245762711864\n",
      "lr.coef_.shape: (1L, 2070L)\n",
      "sumOfSquareAllClasses [5784.5327100648537]\n"
     ]
    }
   ],
   "source": [
    "def empty_preprocessor(s):\n",
    "    return s\n",
    "\n",
    "def better_preprocessor(s):\n",
    "    temp = s.lower().strip()\n",
    "    #tried return re.sub(r'[\\W_]+', '', temp) but result is not as good as only lower and strip\n",
    "    return temp\n",
    "    \n",
    "def P2(train_data, test_data, numOfRun = 3):\n",
    "    cv1 = CountVectorizer(input='content', analyzer = 'word', ngram_range=(1,1), preprocessor = better_preprocessor)\n",
    "    cv_train_data = cv1.fit_transform(train_data)\n",
    "    print 'train_data.shape', train_data.shape\n",
    "    print 'cv_train_data.shape:', cv_train_data.shape\n",
    "    \n",
    "    #save feature names, which will be used later as vocabulary\n",
    "    featureNames = cv1.get_feature_names()\n",
    "    print 'len(featureNames):', len(featureNames)\n",
    "    \n",
    "    #use the same vocabulary to prepare test data\n",
    "    cv2 = CountVectorizer(input='content', vocabulary=featureNames)\n",
    "    cv_test_data = cv2.fit_transform(test_data)\n",
    "    print 'test_data.shape', test_data.shape\n",
    "    print 'cv_test_data.shape', cv_test_data.shape\n",
    "    for i in range(numOfRun):\n",
    "        myKNN(cv_train_data, cv_test_data, i+1)\n",
    "    \n",
    "    for j in np.linspace(0.0, 1.0, num=numOfRun):\n",
    "        myMultinomialNB(cv_train_data, cv_test_data, j)\n",
    "    \n",
    "    for k in range(numOfRun):\n",
    "        myLogisticRegression(cv_train_data, cv_test_data, 10**k * 1.0)\n",
    "P2(train_data_title, test_data_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#So far MultinomialNB with alpha= 1.0 returns best result. Now we will combine both title and text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (1000L,)\n",
      "cv_train_data.shape: (1000, 2070)\n",
      "len(featureNames): 2070\n",
      "test_data.shape (1000L,)\n",
      "cv_test_data.shape (1000, 2070)\n",
      "train_data.shape (1000L,)\n",
      "cv_train_data.shape: (1000, 6015)\n",
      "len(featureNames): 6015\n",
      "test_data.shape (1000L,)\n",
      "cv_test_data.shape (1000, 6015)\n",
      "-------------using MultinomialNB2 -2 data sets- with alpha= 1.0\n",
      "-------------using MultinomialNB with alpha= 1.0\n",
      "total: 1000  correct: 737  accuracy: 0.74\n",
      "metrics.f1_score: 0.120401337793\n",
      "-------------using MultinomialNB with alpha= 1.0\n",
      "total: 1000  correct: 737  accuracy: 0.74\n",
      "metrics.f1_score: 0.0899653979239\n",
      "total: 1000  correct: 715  accuracy: 0.71\n",
      "metrics.f1_score: 0.1642228739\n"
     ]
    }
   ],
   "source": [
    "def myMultinomialNB2(cv_train_data1, cv_test_data1, cv_train_data2, cv_test_data2, a = 1.0):\n",
    "    print '-------------using MultinomialNB2 -2 data sets- with alpha=', a\n",
    "    preds1 = myMultinomialNB(cv_train_data1, cv_test_data1, a)\n",
    "    \n",
    "    preds2 = myMultinomialNB(cv_train_data2, cv_test_data2, a)\n",
    "  \n",
    "    preds = np.zeros(preds1.shape)\n",
    "    i=0\n",
    "    for iPreds1, iPreds2 in zip(preds1, preds2):\n",
    "        if (iPreds1 == 1) or (iPreds2 == 1) : preds[i] = 1\n",
    "        i = i + 1\n",
    "    preditStats(preds, test_labels)\n",
    "    return preds\n",
    "\n",
    "def processData(train_data, test_data):\n",
    "    cv1 = CountVectorizer(input='content', analyzer = 'word', ngram_range=(1,1), preprocessor = better_preprocessor)\n",
    "    cv_train_data = cv1.fit_transform(train_data)\n",
    "    print 'train_data.shape', train_data.shape\n",
    "    print 'cv_train_data.shape:', cv_train_data.shape\n",
    "    \n",
    "    #save feature names, which will be used later as vocabulary\n",
    "    featureNames = cv1.get_feature_names()\n",
    "    print 'len(featureNames):', len(featureNames)\n",
    "    \n",
    "    #use the same vocabulary to prepare test data\n",
    "    cv2 = CountVectorizer(input='content', vocabulary=featureNames)\n",
    "    cv_test_data = cv2.fit_transform(test_data)\n",
    "    print 'test_data.shape', test_data.shape\n",
    "    print 'cv_test_data.shape', cv_test_data.shape\n",
    "    \n",
    "    return cv_train_data, cv_test_data\n",
    "    \n",
    "def P3(train_data1, test_data1, train_data2, test_data2):\n",
    "    \n",
    "    cv_train_data1, cv_test_data1 = processData(train_data1, test_data1)\n",
    "    cv_train_data2, cv_test_data2 = processData(train_data2, test_data2)\n",
    "    \n",
    "    myMultinomialNB2(cv_train_data1, cv_test_data1, cv_train_data2, cv_test_data2, 1.0)\n",
    "  \n",
    "P3(train_data_title, test_data_title, train_data_text, test_data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#needs more work, this does not improve the result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
