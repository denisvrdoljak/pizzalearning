{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "import codecs\n",
    "import json\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "def read_dataset(path):\n",
    "  with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "  dataset = json.loads(content)\n",
    "  return dataset\n",
    "\n",
    "path = 'data/pizza_request_dataset.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data and split into training and dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_all = pd.read_json(path)\n",
    "shuffle = np.random.permutation(np.arange(len(data_all)))\n",
    "data_all = data_all.ix[shuffle]\n",
    "\n",
    "data_all['hour_of_request'] = pd.to_datetime(data_all.unix_timestamp_of_request_utc.values, unit='s').hour\n",
    "data_all['length_of_title'] = [len(entry.split()) for entry in data_all.request_title.values]\n",
    "data_all['length_of_text'] = [len(entry.split()) for entry in data_all.request_text_edit_aware.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631, 17)\n"
     ]
    }
   ],
   "source": [
    "kaggle_test_data = pd.read_json('data/test.json')\n",
    "print kaggle_test_data.shape\n",
    "\n",
    "kaggle_test_data['hour_of_request'] = pd.to_datetime(kaggle_test_data.unix_timestamp_of_request_utc.values, unit='s').hour\n",
    "kaggle_test_data['length_of_title'] = [len(entry.split()) for entry in kaggle_test_data.request_title.values]\n",
    "kaggle_test_data['length_of_text'] = [len(entry.split()) for entry in kaggle_test_data.request_text_edit_aware.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 36)\n",
      "(1702, 36)\n"
     ]
    }
   ],
   "source": [
    "train_all = data_all[:int(len(data_all) * 0.7)]\n",
    "test_all = data_all[int(len(data_all) * 0.7):]\n",
    "\n",
    "print train_all.shape\n",
    "print test_all.shape\n",
    "\n",
    "train_data_text = train_all.request_text_edit_aware.values\n",
    "train_labels = train_all.requester_received_pizza.values\n",
    "\n",
    "test_data_text= test_all.request_text_edit_aware.values\n",
    "test_labels = test_all.requester_received_pizza.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: helper function to easily compare performance\n",
    "def comapre_features(train_data, test_data, text_field = 'request_text_edit_aware', add_features_list=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    train_labels = train_data.requester_received_pizza.values\n",
    "\n",
    "    test_data_text= test_data[text_field].values\n",
    "    test_labels = test_data.requester_received_pizza.values\n",
    "    \n",
    "    vec_train = CountVectorizer()\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "    \n",
    "    LR_train = LogisticRegression()\n",
    "    LR_train.fit(tokenized_train_data,train_labels)\n",
    "\n",
    "    test_pred = LR_train.predict(tokenized_test_data)\n",
    "    print \"------ NLP Baseline: ------\\n\"\n",
    "    print(classification_report(test_labels, test_pred))\n",
    "    print '\\n'\n",
    "    \n",
    "    if add_features_list:\n",
    "        train_token_mat = tokenized_train_data.toarray()\n",
    "        test_token_mat = tokenized_test_data.toarray()\n",
    "        \n",
    "        features_added = []\n",
    "        for feature in add_features_list:\n",
    "            features_added.append(feature)\n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "            \n",
    "            LR_train_plus = LogisticRegression()\n",
    "            LR_train_plus.fit(train_token_mat, train_labels)\n",
    "            test_pred_plus = LR_train_plus.predict(test_token_mat)\n",
    "            print \"--- Features = {feature}: ---\\n\".format(feature=features_added)\n",
    "            print classification_report(test_labels, test_pred_plus)\n",
    "            print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(train_data, test_data, text_field= 'request_text_edit_aware', extra_features=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    if 'requester_received_pizza' in train_data.columns:\n",
    "        train_labels = train_data.requester_received_pizza.values\n",
    "    else:\n",
    "        train_labels = None\n",
    "\n",
    "    test_data_text= test_data[text_field].values\n",
    "    if 'requester_received_pizza' in test_data.columns:\n",
    "        test_labels = test_data.requester_received_pizza.values\n",
    "    else:\n",
    "        test_labels = None\n",
    "    \n",
    "    vec_train = CountVectorizer()\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)    \n",
    "    \n",
    "    train_token_mat = tokenized_train_data.toarray()\n",
    "    test_token_mat = tokenized_test_data.toarray()\n",
    "    \n",
    "    if extra_features:                \n",
    "        for feature in extra_features:            \n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "    \n",
    "    return train_token_mat, train_labels, test_token_mat, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: helper function to make a classifier based on a list of extra features\n",
    "def make_classifier(train_data, test_data, text_field = 'request_text_edit_aware', add_features_list=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    train_labels = train_data.requester_received_pizza.values\n",
    "\n",
    "    test_data_text= test_data[text_field].values    \n",
    "    \n",
    "    vec_train = CountVectorizer()\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)    \n",
    "    \n",
    "    train_token_mat = tokenized_train_data.toarray()\n",
    "    test_token_mat = tokenized_test_data.toarray()\n",
    "    if add_features_list:                \n",
    "        features_added = []\n",
    "        for feature in add_features_list:\n",
    "            features_added.append(feature)\n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "            \n",
    "    LR_train_plus = LogisticRegression()\n",
    "    LR_train_plus.fit(train_token_mat, train_labels)\n",
    "    return LR_train_plus, test_token_mat    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING: Look at subreddits matrix\n",
    "\n",
    "Had this idea: maybe the people giving / requesting pizza belong to a similar group (e.g. gamers tend to give pizzas to fellow gamers, or people who look more 'legit' by the subredits they participate in will tend to receive pizzas)\n",
    "\n",
    "The implementation is simple:\n",
    "1. Extract all the unique subreddits from the training_data as **all_unique_subreddits**\n",
    "2. Construct a matrix for each observation, if the requester has subreddits in ith element of **all_unique_subreddits**, then fill a 1, otherwise 0\n",
    "3. Concatenante this matrix to the tokenized text data\n",
    "4. Train the model with LogisticRegression\n",
    "5. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: a helper function to construct the subreddit matrix for each observation in step 2\n",
    "def make_subreddits_matrix(input_data, unique_subreddits):\n",
    "    results = []\n",
    "    for entry in input_data:\n",
    "        results.append(np.in1d(unique_subreddits, entry))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unique_subreddits = np.unique(np.concatenate(train_all.requester_subreddits_at_request.values))\n",
    "all_unique_subreddits.shape\n",
    "\n",
    "subreddits_matrix_train_all = make_subreddits_matrix(train_all.requester_subreddits_at_request.values, \n",
    "                                                     all_unique_subreddits)\n",
    "subreddits_matrix_test_all = make_subreddits_matrix(test_all.requester_subreddits_at_request.values, \n",
    "                                                    all_unique_subreddits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I just ran a simple Bernoulli Naive-Bayes classifier to do a quick sanity check. If this feature is any good, the NB performance shouldn't be too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(subreddits_matrix_train_all, train_labels)\n",
    "\n",
    "test_pred = nb.predict(subreddits_matrix_test_all)\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if we upsample the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upsample_minority(matrix, labels, random_state=0, ratio=1):\n",
    "    num_positive = labels.sum()\n",
    "    num_negative = len(labels) - num_positive\n",
    "    \n",
    "    if num_negative == num_positive:\n",
    "        return matrix, labels\n",
    "    \n",
    "    minority_count = min(num_positive, num_negative)\n",
    "    majority_count = max(num_positive, num_negative)\n",
    "    \n",
    "    if num_positive >= num_negative:\n",
    "        matrix_minority, labels_minority = matrix[labels == 0, :], labels[labels == 0]        \n",
    "        matrix_majority, labels_majority = matrix[labels == 1, :], labels[labels == 1]        \n",
    "    else:\n",
    "        matrix_minority, labels_minority = matrix[labels == 1, :], labels[labels == 1]\n",
    "        matrix_majority, labels_majority = matrix[labels == 0, :], labels[labels == 0]\n",
    "    \n",
    "    index = np.random.randint(0, high=len(labels_minority),size=(majority_count - minority_count))\n",
    "    extra_matrix_minority, extra_labels_minority = matrix_minority[index, :], labels_minority[index]\n",
    "    matrix_minority = np.concatenate((matrix_minority, extra_matrix_minority))\n",
    "    labels_minority = np.concatenate((labels_minority, extra_labels_minority))\n",
    "    return np.concatenate((matrix_minority, matrix_majority)), np.concatenate((labels_minority, labels_majority))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subreddits_matrix_train_all_upsampled, train_labels_upsampled = upsample_minority(subreddits_matrix_train_all, \n",
    "                                                                                  train_labels)\n",
    "print subreddits_matrix_train_all.shape\n",
    "print subreddits_matrix_train_all_upsampled.shape\n",
    "print train_labels_upsampled.shape\n",
    "print train_labels_upsampled.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_upsampled = BernoulliNB()\n",
    "nb_upsampled.fit(subreddits_matrix_train_all_upsampled, train_labels_upsampled)\n",
    "\n",
    "test_pred_upsampled = nb_upsampled.predict(subreddits_matrix_test_all)\n",
    "print(classification_report(test_labels, test_pred_upsampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite interestingly, using a NB on the subreddits matrix *alone* gives us approximately the same performance we got with tokenizing the texts. Hmm, looks promising. How about we try to make a classifier and see what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_text = train_all.request_text_edit_aware.values\n",
    "train_labels = train_all.requester_received_pizza.values\n",
    "\n",
    "test_data_text= test_all.request_text_edit_aware.values\n",
    "test_labels = test_all.requester_received_pizza.values\n",
    "\n",
    "vec_train = CountVectorizer()\n",
    "tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "\n",
    "train_token_mat = tokenized_train_data.toarray()\n",
    "test_token_mat = tokenized_test_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LR_train_plus = LogisticRegression()\n",
    "LR_train_plus.fit(np.concatenate((train_token_mat, subreddits_matrix_train_all), axis=1), train_labels)\n",
    "\n",
    "test_pred_plus = LR_train_plus.predict(np.concatenate((test_token_mat, subreddits_matrix_test_all), axis=1))\n",
    "print classification_report(test_labels, test_pred_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results on test_data above looks like an overall improvement. Let's go ahead and make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subreddits_kaggle_test_data = make_subreddits_matrix(kaggle_test_data.requester_subreddits_at_request.values,\n",
    "                                                     all_unique_subreddits)\n",
    "\n",
    "tokenized_test_data = vec_test.fit_transform(kaggle_test_data.request_text_edit_aware.values)\n",
    "test_token_mat = tokenized_test_data.toarray()\n",
    "test_token_mat = np.concatenate((test_token_mat, subreddits_kaggle_test_data), axis=1)\n",
    "\n",
    "pred_test_all = LR_train_plus.predict(test_token_mat)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['request_id'] = kaggle_test_data.request_id\n",
    "#maxyan: sample submission was expecting 0 instead of False\n",
    "predictions['requester_received_pizza'] = pred_test_all.astype(int)\n",
    "predictions = predictions.set_index('request_id')\n",
    "\n",
    "# make sure the length is as expected in https://www.kaggle.com/c/random-acts-of-pizza/submissions/attach\n",
    "print len(predictions) == 1631\n",
    "predictions.to_csv('max_nlp_plus_features_submission_v3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the upsampled version\n",
    "\n",
    "Mainly playing around with adding extra features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 12049)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.78      0.77      1258\n",
      "       True       0.33      0.30      0.31       444\n",
      "\n",
      "avg / total       0.65      0.66      0.65      1702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upsampled version\n",
    "EXTRA_FEATURES = ['requester_number_of_posts_on_raop_at_request', \n",
    "                  'requester_number_of_comments_in_raop_at_request',]\n",
    "#                   'requester_upvotes_minus_downvotes_at_request',\n",
    "#                   'requester_account_age_in_days_at_request']\n",
    "\n",
    "train_matrix, train_labels, test_matrix, test_labels = prepare_data(train_all\n",
    "                                                                          , test_all\n",
    "                                                                          , extra_features=EXTRA_FEATURES)\n",
    "\n",
    "print train_matrix.shape\n",
    "\n",
    "# append subreddits features\n",
    "train_matrix = np.concatenate((train_matrix, subreddits_matrix_train_all), axis=1)\n",
    "test_matrix = np.concatenate((test_matrix, subreddits_matrix_test_all), axis=1)\n",
    "\n",
    "train_matrix_upsampled, train_labels_upsampled = upsample_minority(train_matrix, train_labels, random_state=0)\n",
    "\n",
    "LR_upsampled = LogisticRegression()\n",
    "LR_upsampled.fit(train_matrix_upsampled, train_labels_upsampled)\n",
    "\n",
    "test_pred_plus_upsampled = LR_upsampled.predict(test_matrix)\n",
    "print classification_report(test_labels, test_pred_plus_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "subreddits_kaggle_test_data = make_subreddits_matrix(kaggle_test_data.requester_subreddits_at_request.values,\n",
    "                                                     all_unique_subreddits)\n",
    "\n",
    "_, _, test_token_mat, _ = prepare_data(train_all\n",
    "                                       , kaggle_test_data\n",
    "                                       , extra_features=EXTRA_FEATURES)\n",
    "\n",
    "# append subreddits features\n",
    "test_token_mat = np.concatenate((test_token_mat, subreddits_kaggle_test_data), axis=1)\n",
    "\n",
    "pred_test_all = LR_upsampled.predict(test_token_mat)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['request_id'] = kaggle_test_data.request_id\n",
    "#maxyan: sample submission was expecting 0 instead of False\n",
    "predictions['requester_received_pizza'] = pred_test_all.astype(int)\n",
    "predictions = predictions.set_index('request_id')\n",
    "\n",
    "# make sure the length is as expected in https://www.kaggle.com/c/random-acts-of-pizza/submissions/attach\n",
    "print len(predictions) == 1631\n",
    "predictions.to_csv('max_upsampled_submission_v4_with_subreddits_2_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some final words on my bit of exploration**\n",
    "\n",
    "Throughout the exercise, I used the originally shuffled and *splitted* data for training and testing. I haven't bothered making any changes. I'm not sure if we can further improve the performance if we took the entire dataset for training.\n",
    "\n",
    "\n",
    "Also, I have been using Ricardo's dataset (i.e. 'data/pizza_request_dataset.json') rather than the one provided by Kaggle. I think there are some differences but I haven't figured out what exactly these differences are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec_train = CountVectorizer()\n",
    "tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "\n",
    "print tokenized_train_data.shape\n",
    "print tokenized_test_data.shape\n",
    "\n",
    "LR_train = LogisticRegression()\n",
    "LR_train.fit(tokenized_train_data,train_labels)\n",
    "\n",
    "test_pred = LR_train.predict(tokenized_test_data)\n",
    "\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(kaggle_test_data.columns.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comapre_features(train_all, \n",
    "                 test_all, \n",
    "                 add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                   'requester_number_of_subreddits_at_request',\n",
    "                                   'requester_upvotes_minus_downvotes_at_request',\n",
    "                                   'length_of_text',\n",
    "                                   'length_of_title',\n",
    "                                   'hour_of_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comapre_features(train_all, \n",
    "                 test_all, \n",
    "                 text_field='request_title',\n",
    "                 add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                   'requester_number_of_subreddits_at_request',\n",
    "                                   'requester_upvotes_minus_downvotes_at_request',\n",
    "                                   'length_of_text',\n",
    "                                   'length_of_title',\n",
    "                                   'hour_of_request'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a classifier and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kaggle_test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier, kaggle_test_mat = make_classifier(train_all, \n",
    "                                              kaggle_test_data, \n",
    "                                              add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                                                 'requester_number_of_subreddits_at_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier, kaggle_test_mat = make_classifier(train_all, \n",
    "                                              kaggle_test_data, \n",
    "                                              add_features_list=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_test_all = classifier.predict(kaggle_test_mat)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['request_id'] = kaggle_test_data.request_id\n",
    "#maxyan: sample submission was expecting 0 instead of False\n",
    "predictions['requester_received_pizza'] = pred_test_all.astype(int)\n",
    "predictions = predictions.set_index('request_id')\n",
    "\n",
    "# make sure the length is as expected in https://www.kaggle.com/c/random-acts-of-pizza/submissions/attach\n",
    "print len(predictions) == 1631\n",
    "predictions.to_csv('max_nlp_plus_features_submission_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
