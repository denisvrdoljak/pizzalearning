{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 5671 samples.\n",
      "Available attributes:  [u'giver_username_if_known', u'in_test_set', u'number_of_downvotes_of_request_at_retrieval', u'number_of_upvotes_of_request_at_retrieval', u'post_was_edited', u'request_id', u'request_number_of_comments_at_retrieval', u'request_text', u'request_text_edit_aware', u'request_title', u'requester_account_age_in_days_at_request', u'requester_account_age_in_days_at_retrieval', u'requester_days_since_first_post_on_raop_at_request', u'requester_days_since_first_post_on_raop_at_retrieval', u'requester_number_of_comments_at_request', u'requester_number_of_comments_at_retrieval', u'requester_number_of_comments_in_raop_at_request', u'requester_number_of_comments_in_raop_at_retrieval', u'requester_number_of_posts_at_request', u'requester_number_of_posts_at_retrieval', u'requester_number_of_posts_on_raop_at_request', u'requester_number_of_posts_on_raop_at_retrieval', u'requester_number_of_subreddits_at_request', u'requester_received_pizza', u'requester_subreddits_at_request', u'requester_upvotes_minus_downvotes_at_request', u'requester_upvotes_minus_downvotes_at_retrieval', u'requester_upvotes_plus_downvotes_at_request', u'requester_upvotes_plus_downvotes_at_retrieval', u'requester_user_flair', u'requester_username', u'unix_timestamp_of_request', u'unix_timestamp_of_request_utc']\n",
      "First post:\n",
      "{\n",
      "  \"giver_username_if_known\": \"N/A\", \n",
      "  \"in_test_set\": false, \n",
      "  \"number_of_downvotes_of_request_at_retrieval\": 2, \n",
      "  \"number_of_upvotes_of_request_at_retrieval\": 6, \n",
      "  \"post_was_edited\": false, \n",
      "  \"request_id\": \"t3_w5491\", \n",
      "  \"request_number_of_comments_at_retrieval\": 7, \n",
      "  \"request_text\": \"I'm not in College, or a starving artist or anything like that. I've just been a bit unlucky lately. I'm a 36 year old single guy with a job. But rent, and other bills killed me this month. I thought I had enough funds in my account to at least keep me set with Mr. Noodles, I forgot about my monthly banking fee.\\n\\nI had a small bag of chips Wednesday afternoon, and I get paid Monday, so I'll be fine then.. It's just really painful at this point and food is something I'm constantly thinking about.\\n\\nI've got a few bucks to get on the bus to work on Saturday, so I can't really use that.\\n\\nI'm really embarrassed to even be asking like this and I'm not sure how it works, so please be patient with me.\\n\\nI guess that covers it. Thank you in advance.\\n\\nCheers folks.\", \n",
      "  \"request_text_edit_aware\": \"I'm not in College, or a starving artist or anything like that. I've just been a bit unlucky lately. I'm a 36 year old single guy with a job. But rent, and other bills killed me this month. I thought I had enough funds in my account to at least keep me set with Mr. Noodles, I forgot about my monthly banking fee.\\n\\nI had a small bag of chips Wednesday afternoon, and I get paid Monday, so I'll be fine then.. It's just really painful at this point and food is something I'm constantly thinking about.\\n\\nI've got a few bucks to get on the bus to work on Saturday, so I can't really use that.\\n\\nI'm really embarrassed to even be asking like this and I'm not sure how it works, so please be patient with me.\\n\\nI guess that covers it. Thank you in advance.\\n\\nCheers folks.\", \n",
      "  \"request_title\": \"[Request] Ontario, Canada - On my 3rd of 5 days without food, and it's getting unbearable. Can anyone help?\", \n",
      "  \"requester_account_age_in_days_at_request\": 14.416875, \n",
      "  \"requester_account_age_in_days_at_retrieval\": 531.9697222222222, \n",
      "  \"requester_days_since_first_post_on_raop_at_request\": 0.0, \n",
      "  \"requester_days_since_first_post_on_raop_at_retrieval\": 517.5111805555556, \n",
      "  \"requester_number_of_comments_at_request\": 8, \n",
      "  \"requester_number_of_comments_at_retrieval\": 93, \n",
      "  \"requester_number_of_comments_in_raop_at_request\": 0, \n",
      "  \"requester_number_of_comments_in_raop_at_retrieval\": 4, \n",
      "  \"requester_number_of_posts_at_request\": 1, \n",
      "  \"requester_number_of_posts_at_retrieval\": 6, \n",
      "  \"requester_number_of_posts_on_raop_at_request\": 0, \n",
      "  \"requester_number_of_posts_on_raop_at_retrieval\": 2, \n",
      "  \"requester_number_of_subreddits_at_request\": 8, \n",
      "  \"requester_received_pizza\": true, \n",
      "  \"requester_subreddits_at_request\": [\n",
      "    \"AdviceAnimals\", \n",
      "    \"WTF\", \n",
      "    \"funny\", \n",
      "    \"gaming\", \n",
      "    \"movies\", \n",
      "    \"technology\", \n",
      "    \"todayilearned\", \n",
      "    \"videos\"\n",
      "  ], \n",
      "  \"requester_upvotes_minus_downvotes_at_request\": 32, \n",
      "  \"requester_upvotes_minus_downvotes_at_retrieval\": 212, \n",
      "  \"requester_upvotes_plus_downvotes_at_request\": 48, \n",
      "  \"requester_upvotes_plus_downvotes_at_retrieval\": 610, \n",
      "  \"requester_user_flair\": \"shroom\", \n",
      "  \"requester_username\": \"RitalinYourMemory\", \n",
      "  \"unix_timestamp_of_request\": 1341604684.0, \n",
      "  \"unix_timestamp_of_request_utc\": 1341601084.0\n",
      "}\n",
      "The average success rate is: 24.63%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import codecs\n",
    "import json\n",
    "import itertools\n",
    "import csv\n",
    "\n",
    "def read_dataset(path):\n",
    "  with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "  dataset = json.loads(content)\n",
    "  return dataset\n",
    "\n",
    "path = 'data/pizza_request_dataset.json'\n",
    "dataset = read_dataset(path)\n",
    "\n",
    "print 'The dataset contains %d samples.' %(len(dataset))\n",
    "print 'Available attributes: ', sorted(dataset[0].keys())\n",
    "print 'First post:'\n",
    "print json.dumps(dataset[0], sort_keys=True, indent=2)\n",
    "\n",
    "successes = [r['requester_received_pizza'] for r in dataset]\n",
    "success_rate = 100.0 * sum(successes) / float(len(successes))\n",
    "print 'The average success rate is: %.2f%%' %(success_rate)\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data and split into training and dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_all = pd.read_json(path)\n",
    "data_all = data_all.ix[shuffle]\n",
    "\n",
    "data_all['hour_of_request'] = pd.to_datetime(data_all.unix_timestamp_of_request_utc.values, unit='s').hour\n",
    "data_all['length_of_title'] = [len(entry.split()) for entry in data_all.request_title.values]\n",
    "data_all['length_of_text'] = [len(entry.split()) for entry in data_all.request_text_edit_aware.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631, 17)\n"
     ]
    }
   ],
   "source": [
    "kaggle_test_data = pd.read_json('data/test.json')\n",
    "print kaggle_test_data.shape\n",
    "\n",
    "kaggle_test_data['hour_of_request'] = pd.to_datetime(kaggle_test_data.unix_timestamp_of_request_utc.values, unit='s').hour\n",
    "kaggle_test_data['length_of_title'] = [len(entry.split()) for entry in kaggle_test_data.request_title.values]\n",
    "kaggle_test_data['length_of_text'] = [len(entry.split()) for entry in kaggle_test_data.request_text_edit_aware.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 36)\n",
      "(1702, 36)\n"
     ]
    }
   ],
   "source": [
    "train_all = data_all[:int(len(data_all) * 0.7)]\n",
    "test_all = data_all[int(len(data_all) * 0.7):]\n",
    "\n",
    "print train_all.shape\n",
    "print test_all.shape\n",
    "\n",
    "train_data_text = train_all.request_text_edit_aware.values\n",
    "train_labels = train_all.requester_received_pizza.values\n",
    "\n",
    "test_data_text= test_all.request_text_edit_aware.values\n",
    "test_labels = test_all.requester_received_pizza.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: helper function to easily compare performance\n",
    "def comapre_features(train_data, test_data, text_field = 'request_text_edit_aware', add_features_list=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    train_labels = train_data.requester_received_pizza.values\n",
    "\n",
    "    test_data_text= test_data[text_field].values\n",
    "    test_labels = test_data.requester_received_pizza.values\n",
    "    \n",
    "    vec_train = CountVectorizer()\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "    \n",
    "    LR_train = LogisticRegression()\n",
    "    LR_train.fit(tokenized_train_data,train_labels)\n",
    "\n",
    "    test_pred = LR_train.predict(tokenized_test_data)\n",
    "    print \"------ NLP Baseline: ------\\n\"\n",
    "    print(classification_report(test_labels, test_pred))\n",
    "    print '\\n'\n",
    "    \n",
    "    if add_features_list:\n",
    "        train_token_mat = tokenized_train_data.toarray()\n",
    "        test_token_mat = tokenized_test_data.toarray()\n",
    "        \n",
    "        features_added = []\n",
    "        for feature in add_features_list:\n",
    "            features_added.append(feature)\n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "            \n",
    "            LR_train_plus = LogisticRegression()\n",
    "            LR_train_plus.fit(train_token_mat, train_labels)\n",
    "            test_pred_plus = LR_train_plus.predict(test_token_mat)\n",
    "            print \"--- Features = {feature}: ---\\n\".format(feature=features_added)\n",
    "            print classification_report(test_labels, test_pred_plus)\n",
    "            print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myan: helper function to make a classifier based on a list of extra features\n",
    "def make_classifier(train_data, test_data, text_field = 'request_text_edit_aware', add_features_list=None):\n",
    "    train_data_text = train_data[text_field].values\n",
    "    train_labels = train_data.requester_received_pizza.values\n",
    "\n",
    "    test_data_text= test_data[text_field].values    \n",
    "    \n",
    "    vec_train = CountVectorizer()\n",
    "    tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "    vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "    tokenized_test_data = vec_test.fit_transform(test_data_text)    \n",
    "    \n",
    "    if add_features_list:\n",
    "        train_token_mat = tokenized_train_data.toarray()\n",
    "        test_token_mat = tokenized_test_data.toarray()\n",
    "        \n",
    "        features_added = []\n",
    "        for feature in add_features_list:\n",
    "            features_added.append(feature)\n",
    "            train_token_mat = np.concatenate((train_token_mat, np.array([train_data[feature].values]).T), axis=1)\n",
    "            test_token_mat = np.concatenate((test_token_mat, np.array([test_data[feature].values]).T), axis=1)\n",
    "            \n",
    "        LR_train_plus = LogisticRegression()\n",
    "        LR_train_plus.fit(train_token_mat, train_labels)\n",
    "        return LR_train_plus, test_token_mat\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3969, 12174)\n",
      "(1702, 12174)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.88      0.82      1281\n",
      "       True       0.35      0.20      0.26       421\n",
      "\n",
      "avg / total       0.66      0.71      0.68      1702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_train = CountVectorizer()\n",
    "tokenized_train_data = vec_train.fit_transform(train_data_text)\n",
    "\n",
    "vec_test = CountVectorizer(vocabulary=vec_train.vocabulary_)\n",
    "tokenized_test_data = vec_test.fit_transform(test_data_text)\n",
    "\n",
    "print tokenized_train_data.shape\n",
    "print tokenized_test_data.shape\n",
    "\n",
    "LR_train = LogisticRegression()\n",
    "LR_train.fit(tokenized_train_data,train_labels)\n",
    "\n",
    "test_pred = LR_train.predict(tokenized_test_data)\n",
    "\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1631, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['giver_username_if_known',\n",
       " 'request_id',\n",
       " 'request_text_edit_aware',\n",
       " 'request_title',\n",
       " 'requester_account_age_in_days_at_request',\n",
       " 'requester_days_since_first_post_on_raop_at_request',\n",
       " 'requester_number_of_comments_at_request',\n",
       " 'requester_number_of_comments_in_raop_at_request',\n",
       " 'requester_number_of_posts_at_request',\n",
       " 'requester_number_of_posts_on_raop_at_request',\n",
       " 'requester_number_of_subreddits_at_request',\n",
       " 'requester_subreddits_at_request',\n",
       " 'requester_upvotes_minus_downvotes_at_request',\n",
       " 'requester_upvotes_plus_downvotes_at_request',\n",
       " 'requester_username',\n",
       " 'unix_timestamp_of_request',\n",
       " 'unix_timestamp_of_request_utc']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kaggle_test_data.columns.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ NLP Baseline: ------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.88      0.82      1281\n",
      "       True       0.35      0.20      0.26       421\n",
      "\n",
      "avg / total       0.66      0.71      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.87      0.82      1281\n",
      "       True       0.36      0.22      0.27       421\n",
      "\n",
      "avg / total       0.67      0.71      0.69      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.87      0.82      1281\n",
      "       True       0.37      0.23      0.28       421\n",
      "\n",
      "avg / total       0.67      0.71      0.69      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.77      0.87      0.82      1281\n",
      "       True       0.36      0.23      0.28       421\n",
      "\n",
      "avg / total       0.67      0.71      0.69      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.88      0.82      1281\n",
      "       True       0.38      0.23      0.28       421\n",
      "\n",
      "avg / total       0.68      0.72      0.69      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.88      0.82      1281\n",
      "       True       0.38      0.23      0.28       421\n",
      "\n",
      "avg / total       0.68      0.72      0.69      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title', 'hour_of_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.88      0.82      1281\n",
      "       True       0.38      0.23      0.28       421\n",
      "\n",
      "avg / total       0.68      0.72      0.69      1702\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comapre_features(train_all, \n",
    "                 test_all, \n",
    "                 add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                   'requester_number_of_subreddits_at_request',\n",
    "                                   'requester_upvotes_minus_downvotes_at_request',\n",
    "                                   'length_of_text',\n",
    "                                   'length_of_title',\n",
    "                                   'hour_of_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ NLP Baseline: ------\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.91      0.83      1281\n",
      "       True       0.29      0.11      0.16       421\n",
      "\n",
      "avg / total       0.64      0.71      0.66      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.91      0.83      1281\n",
      "       True       0.30      0.11      0.16       421\n",
      "\n",
      "avg / total       0.64      0.71      0.66      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.91      0.83      1281\n",
      "       True       0.32      0.13      0.18       421\n",
      "\n",
      "avg / total       0.65      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.91      0.83      1281\n",
      "       True       0.32      0.13      0.18       421\n",
      "\n",
      "avg / total       0.65      0.72      0.67      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.92      0.83      1281\n",
      "       True       0.36      0.14      0.20       421\n",
      "\n",
      "avg / total       0.66      0.73      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.92      0.83      1281\n",
      "       True       0.35      0.14      0.20       421\n",
      "\n",
      "avg / total       0.66      0.72      0.68      1702\n",
      "\n",
      "\n",
      "\n",
      "--- Features = ['requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'length_of_text', 'length_of_title', 'hour_of_request']: ---\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.76      0.92      0.83      1281\n",
      "       True       0.35      0.13      0.19       421\n",
      "\n",
      "avg / total       0.66      0.72      0.68      1702\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comapre_features(train_all, \n",
    "                 test_all, \n",
    "                 text_field='request_title',\n",
    "                 add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                   'requester_number_of_subreddits_at_request',\n",
    "                                   'requester_upvotes_minus_downvotes_at_request',\n",
    "                                   'length_of_text',\n",
    "                                   'length_of_title',\n",
    "                                   'hour_of_request'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a classifier and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier, kaggle_test_mat = make_classifier(train_all, \n",
    "                                              kaggle_test_data, \n",
    "                                              add_features_list=['requester_number_of_posts_on_raop_at_request',                                    \n",
    "                                                                   'requester_number_of_subreddits_at_request'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "pred_test_all = classifier.predict(kaggle_test_mat)\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "predictions['request_id'] = kaggle_test_data.request_id\n",
    "#maxyan: sample submission was expecting 0 instead of False\n",
    "predictions['requester_received_pizza'] = pred_test_all.astype(int)\n",
    "predictions = predictions.set_index('request_id')\n",
    "\n",
    "# make sure the length is as expected in https://www.kaggle.com/c/random-acts-of-pizza/submissions/attach\n",
    "print len(predictions) == 1631\n",
    "predictions.to_csv('max_nlp_plus_features_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
